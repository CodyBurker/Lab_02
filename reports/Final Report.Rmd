---
title: "Research Proposal: How are state policies and population related to the state-wide spread of COVID-19?"
author: 'Cody Burker, Emily Fernandes, Margo Suryanaga'
output: bookdown::pdf_document2
---

```{r setup&getdata, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readxl)
library("data.table")
library("ggplot2")
library("lubridate")
library("dplyr")
library("zoo")
library(naniar)
library(patchwork)
library(sandwich)
library(lmtest)
library(nortest)
library(HH)
library(lattice)

calc_num_days <- function(str,end,end.date) {
   str[str=="NA"] = end.date
   end[end=="NA"] = end.date
   
   
   end.date = as.Date(end.date)
   str=as.Date(str)
   
   end=as.Date(end)
   end[end> end.date] = end.date

   ind = end-str
   
   ind[ind <= 0] = 0  
   ind = as.numeric(ind)
   
   df <- data.frame (STR  = str,END = end, DIFF = ind)
   
  return(ind)
}
calc_num_days_n <- function(str,end,end.date) {
   str[str=="NA"] = end.date
   end[end=="NA"] = end.date
   
   
   end.date = as.Date(end.date)
   str=as.Date(str)
   
   end=as.Date(end)
   end[end> end.date] = end.date

   ind = end-str
   ind = as.numeric(ind)
   df <- data.frame (STR  = str,END = end, DIFF = ind)
   print(df)
   
  return(ind)
}

#Collect NYT's Covid-19 Data
NYT_Data <- fread("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")
NYT_Data

str.date = "2020-01-20"
end.date = "2020-05-31"

ref.date.list = seq(as.Date(str.date), as.Date(end.date), by="days")

#Treat Dates as Dates
NYT_Data[,date:=as.Date(date)]
NYT_Data <- NYT_Data[NYT_Data$date==end.date,]


#Collect CUSP Policy Data
CUSP_Data=read.csv("CUSP_Clean.csv",na.strings = c(0))
CUSP_Data$state = CUSP_Data$State

#Merge Data
total_data = merge(NYT_Data, CUSP_Data, by = "state")
total_data<-total_data[order(total_data$state,total_data$date), ]

date = ref.date.list
##Create Stay Home Variables 
str1.stay.home.date = total_data$Stay.at.home.shelter.in.place
str2.stay.home.date = total_data$Stay.at.home.order.issued.but.did.not.specifically.restrict.movement.of.the.general.public
str.stay.home.date <- ifelse(str1.stay.home.date=='NA', str2.stay.home.date, str1.stay.home.date)
end.stay.home.date = total_data$End.stay.at.home.shelter.in.place

total_data$stay.home.total=calc_num_days(str.stay.home.date,end.stay.home.date,end.date)

##Create School Variables
str.school.date = total_data$Closed.K.12.public.schools
end.school.date = rep( end.date, length(str.school.date))

total_data$close.school.total=calc_num_days(str.school.date,end.school.date,end.date)


##Create Face Mask and Travel Variables 
str.maskB.date = total_data$Business.face.mask.mandate
str.travel.date.all = total_data$Quarantine.mandate.for.all.travelers
str.travel.date.some = total_data$Quarantine.mandate.for.some.travelers
str.travel.date <- ifelse(str.travel.date.all=='NA', str.travel.date.some, str.travel.date.all)

end.maskB.date = total_data$End.face.mask.mandate
end.travel.date = total_data$Quarantine.mandate.ended

total_data$maskB.total=calc_num_days(str.maskB.date,end.maskB.date,end.date)
total_data$travel.total=calc_num_days(str.travel.date,end.travel.date,end.date)

#Round 1 Shutdowns
str.res1.date = total_data$Closed.restaurants
end.res1.date = total_data$Reopened.restaurants

str.gym1.date = total_data$Closed.gyms
end.gym1.date = total_data$Reopened.gyms

str.bar1.date = total_data$Closed.bars
end.bar1.date = total_data$Reopened.bars   

total_data$res1.total=calc_num_days(str.res1.date,end.res1.date,end.date)
total_data$gym1.total=calc_num_days(str.gym1.date,end.gym1.date,end.date)
total_data$bar1.total=calc_num_days(str.bar1.date,end.bar1.date,end.date)

#Include Popluation Data
total_data$population = as.numeric(total_data$Population.2018)
total_data$population.density = as.numeric(total_data$Population.density.per.square.mile)
total_data$cases = as.numeric(total_data$cases)
   
#Create Speed Variables
pandemic_date = rep('2020-03-11', length(str.stay.home.date))  
stayAtHomeSincePandemic = calc_num_days_n(str.stay.home.date, pandemic_date,end.date)

state.of.emergency = total_data$State.of.emergency
state.of.emergency.speed = calc_num_days_n(state.of.emergency, pandemic_date,end.date)


#Transformations
Model_Data=total_data
Model_Data$case.per.100k = (Model_Data$cases/Model_Data$population)*100000
Model_Data$case.log = log(Model_Data$case.per.100k)
Model_Data$population.density.log = log(Model_Data$population.density)

#Base Model
model1 = lm(case.log~population.density.log, data = Model_Data)
#Medium Model
model2 = lm(case.log~population.density.log+
                      maskB.total+ 
                      stay.home.total+
                      travel.total, data = Model_Data)
#Complex Model
model3 = lm(case.log~population.density.log+
                      maskB.total+
                      stay.home.total+
                      travel.total+
                      res1.total+
                      bar1.total+
                      gym1.total+ 
                      state.of.emergency.speed, data = Model_Data)
```


# Background

The COVID-19 pandemic is the first pandemic seen in a century, affecting each individual worldwide. While many countries issued lockdowns, travel quarantines, and other COVID-19 restrictions on a federal level, the US federal government placed the power with the governors to regulate the implementation of these restrictions on a state-by-state basis.

There has been increased skepticism on the true effectiveness of restrictions in slowing down the spread of COVID-19, especially due to the amount of economic impact resulting from these procedures. Evaluating how each state's population density, lockdown procedures, and facemask policies correlates to the spread of COVID-19 within that state helps citizens understand the importance of following these policies. Understanding the effectiveness of COVID-19 restrictions in slowing the spread of the disease also helps policy makers justify the implementation of these policies to their constituents. Additionally, this information might be of interest to public health officials who are looking for best practices to contain a future pandemic or infectious disease.

# Data sources

1.  [COVID-19 US State Policy Database](www.tinyurl.com/statepolicies) A database of state policy responses to the pandemic, compiled by researchers at the Boston University School of Public Health.
2.  [NY Times Covid-19 Data Repository](https://github.com/nytimes/covid-19-data) A series of data files with cumulative counts of coronavirus cases in the United States, at the state and county level, over time.

From data source (1), we expect to get:\
- Closure and reopenings: Start and end dates of closures of public spaces\
- Stay at home: Start and end dates of stay at home policies\
- Face masks: Start and end date of face mask mandates\
From data source (2) we expect to get:\
- Weekly COVID-19 case counts

# Methodology and Expected outcome

Our team would like to study the initial spread of the Covid-19 virus, from the first case seen in the United States until May 31st. Our goal was to create a series of models to explain the relationship between the various state policies put in place to curtail the spread of the virus and the number of cases observed in each state. In the analysis we will use the following policies as input variables:
*Business mask mandate (measured in days the policy was in place)
*Stay at home/shelter in place order (measured in days the policy was in place)
*Interstate travel quarantines (measured in days the policy was in place)
*Restaurant/Bar/Gym Shutdowns (measured in days the policy was in place)
*Shutdown declared in relationship to day 
*State of Emergency declared in relationship to 3-11-2020 (Date that the World Health Organization declared the Covid-19 Pandemic) relationship to 3-11-2020 (Date that the World Health Organization declared the Covid-19 Pandemic)

We understand that the spread of Covid-19 is also influenced by not just state policies, but also by the relative closeness of people within each state. In an effort to capture this, we will also include the population density as an input variable. With these inputs, we hope to explain which state policies were effective at curtailing the initial spread of the Covid-19 virus. For each model we will evaluate the sssumptions for a Classical Linera Model. These requirements are:

1. I.I.D. 
2. Linear Conditional Expectation Exists
3. No Colinearity
4. No Homoskedastic Error
5. Normal Residuals

The data use for the following models 

First, we began to explore the number of cases in each state per 100,000 residents. This allowed us to account for the number of cases while equalizing the predicted variable to account for the fact that New York or California will have a much larger number of cases than Alaska simple due to the fact these states have many more residents. After viewing the histogram of the number of cases per state per 100k residents, our team chose to handle the skew of the data by completeing a log transformation. The histogram of the log transformed variable can be seen below.
```{r echo=FALSE, message=FALSE, warning=FALSE}
require(gridExtra)
hist1<-ggplot(Model_Data, aes(x=case.per.100k)) + 
   geom_histogram(color="black", fill="grey")+
   ylab('Frequency')+xlab('Number of Cases per 100k State Residents')+
   ggtitle('Predicted Variable Histograms')+
  theme(plot.title = element_text(hjust = 0.5))
hist2<-ggplot(Model_Data, aes(x=case.log)) + 
   geom_histogram(color="black", fill="grey")+
   ylab('Frequency')+xlab('Log of Number of Cases per 100k State Residents')
grid.arrange(hist1, hist2, nrow=2) 
```


For our base model, we chose to select the one input variable that was a characteristic of the state and not a policy enacted by the state. We hypothesize that the state's population density is one of the first building blocks to describe the number of cases in that state on May 31st, 2020. Close human contact is how this virus spreads and population density captures the relative closeness of residents in a state. Again, after viewing the initial highly skewed histogram we chose to complete a log transformation of this variable. The transformed histogram can be seen below.
```{r echo=FALSE, message=FALSE, warning=FALSE}
hist1<-ggplot(Model_Data, aes(x=population.density)) + 
   geom_histogram(color="black", fill="grey")+
   ylab('Frequency')+xlab("State's Polulation Density (People per square mile) ")+
   ggtitle('Input Variable Histograms')+
  theme(plot.title = element_text(hjust = 0.5))
hist2<-ggplot(Model_Data, aes(x=population.density.log)) + 
   geom_histogram(color="black", fill="grey")+
   ylab('Frequency')+xlab("Log of State's Polulation Density")
grid.arrange(hist1, hist2, nrow=2) 
```
Our base model will look at the log relationship of each state's cases on May 31st, 2020 per 100k residents with that state's population density. 
```{r echo=FALSE, message=FALSE, warning=FALSE}
Model_Data <- Model_Data %>%  mutate(model1_res = resid(model1))
Model_Data <- Model_Data %>% mutate(model1_prd = predict(model1)) 

#Create a scatterplot with current model's regression line
Regression_Plot <- ggplot(Model_Data, aes(x = population.density.log, y = case.log)) + 
      geom_point()+
      geom_line(data = Model_Data, 
                aes(x = population.density.log, y = model1_prd))+
      ggtitle(paste('Relationship of Log(Covid-19 Cases per 100k Residents)',
                    '\n', 'and Log(Population Density)'))+
      ylab(paste('Log(Covid-19 Cases', '\n','per 100k Residents)'))+
      xlab('Log(Population Density)')+geom_point()

#Residuals versus Predictors
Residuals_Plot = ggplot(data = Model_Data, aes(x = model1_prd, y = model1_res)) + 
  geom_point() + stat_smooth(se = TRUE)+
  ylab('Base Model Residuals')+xlab('Predictors')

#Histogram of Residuals
Normal_Residuals<-ggplot(Model_Data, aes(x=model1_res)) + 
   geom_histogram(color="black", fill="grey")+
   ylab('Frequency')+xlab("Base Model Residuals")

grid.arrange(Regression_Plot, Residuals_Plot,nrow=2) 
```
From the Residual/Predictors plot shown above, one can see that this basic model's predictors has a fairly linear relationship with residuals implying that a Linear Conditional Expectation exists. Colinearlity cannot exist for this base model because we only have 1 input variable. The Residual/Predictors plot displays a flaring of the standard error at the extremes which implies the potential for Homoskedastic errors, therefore we will use robust standard error when reviewing the significance level of this model's coefficients. Lastly we have a plot of the basic model's residuals to ensure they are normal. As you can see from the histogram below, the residual's are in fact normally distributed. 
```{r echo=FALSE, message=FALSE, warning=FALSE}
#shapiro.test(Model_Data$model1_res)
Normal_Residuals
```

For our next model, we chose to build off the basic model while adding several inputs to represent key state policies. This next model will also account for the number of days each state had a:
*Business mask mandate
*Stay at home/shelter in place order
*Interstate travel quarantine

We first 




# Regression Table

Table \@ref(tab:regression) displays the regression of all 3 models. We are use robust standard error. 


```{r regression, echo=FALSE, message=FALSE, warning=FALSE, results="asis"}
# Assumes that the following models are in-memory:
# model1
# model2
# model3
library(stargazer)
library(sandwich)
library(lmtest)
library(tidyverse)

# Adjust standard errors
cov1 <- vcovHC(model1)
rse1 <- sqrt(diag(cov1))
cov2 <- vcovHC(model2)
rse2 <- sqrt(diag(cov2))
cov3 <- vcovHC(model3)
rse3 <- sqrt(diag(cov3))

p_val1 <- coeftest(model1, vcov. = cov1)[,4]
p_val2 <- coeftest(model2, vcov. = cov2)[,4]
p_val3 <- coeftest(model3, vcov. = cov3)[,4]

# Get new f statistics
f_stat1 <- waldtest(model1, vcov = cov1)
f_stat2 <- waldtest(model2, vcov = cov2)
f_stat3 <- waldtest(model3, vcov = cov3)

# Create string array of modified F statistic
f_stat_string = c("F-Statistic",
                        paste(round(f_stat1$F[2],3),"***"," (df = 1; 49)", sep=""),
                        paste(round(f_stat1$F[2],3),"***"," (df = 5; 45)", sep=""),
                        paste(round(f_stat3$F[2],3),"***"," (df = 9; 41)", sep="")
           )

stargazer(model1, model2, model3, type="latex",
          title = "Regression Table",
          covariate.labels = c("Log (Population Density)",
                               "Business mask mandate (days)",
                               "Stay at home/shelter in place order (days)",
                               "Interstate Travel Quarantine In Place Length (days)",
                               "Restaurant Shutdown Length (days)",
                               "Bar Shutdown Length (days)",
                               "Gym Shutdown Length (days)",
                               "State of Emergency Speed (days)"
          ),
          dep.var.labels = c(""),
          dep.var.caption = "Dependent Variable: Log (Covid-19 Cases)",
          column.labels = c("Simple Model","Moderate Model","Complex Model"),
          se = list(rse1, rse2, rse3),
          omit.stat = "f",
          add.lines = list(f_stat_string),
          header=FALSE,
          label = "tab:regression",
          p = list(p_val1, p_val2, p_val3)
)
```
## Model 1

We will begin by inspecting the first Model in Table \@ref(tab:regression). Here we see a significant relationship between Log (Population Density) and Log (Covid-19 Cases). Figure  \@ref(tab:regression) displays a scatterplot of the two, and we do see some relationship. The coeffeficient is positive, indicating that a higher density is related to a larger number of Covid-19 cases per 100,000 people in a state. Because (using robust standard errors) this relationship is significant (p < 0.001) we reject the hypothesis that there is no relationship between Log (Population Density) and Log(Covid-19 Cases) in favor of the hypothesis that there is a relationship. The following model was used to test the relationship between the two variables:

$$
\log (\text{Covid-19 Cases}) = \beta_0 + \beta_1 \log (\text{Population Density}) \\
$$


This model implies that  every percent increase in Population Density (measured in people / square mile) causes a `r model1$coefficients[2] %>% format(digits=2)`% increase in Covid19 Cases per 100,000 people in a state, which has much practical significance. While it is likely not feasible to reduce Population Density, this number might inform policy makers as to which states are more vulnerable to future pandemics. Also, this model has an $R^2$ value of `r format(summary(model1)$r.squared, digits=2)`, it seems as if the transformed population density accounts for a surprising amount of the variance in Log (Covid19 Cases).

```{r covid-density-scatter, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Scatterplot of Model1"}
ggplot(Model_Data, aes(y=case.log, x=population.density.log)) + 
  geom_point() + 
  geom_smooth(method="lm", se = FALSE) + 
  labs(title = "Model 1: Log Population Density vs Log Covid-19 Cases",
       x = "Log Population Density" , y = "Log Covid-19 Cases")
```

## Model 2

For our second model, we find evidence that there is a relationship between how long states took to enact business mask mandates after the pandemic was declared (Business mask Mandate), how long the stay at home order was in place (Stay at home/shelter in place order), and how long the interstate travel quarantine was in place (Interstate Travel Quarantine In Place Length) in addition to the Log (Population Density). The coefficient for Log (Population Density) decreases from 0.358 to 0.329 (but remains significant), indicating that some of its explanatory power is shared between the other variables we have included (and also perhaps there is a small amount of colinearity between this variable and one or more of the others). 

When we inspect the Stay at home/shelter in place order coefficient, we see that it is both significant and negative This indicates that for every extra day that a state spend with a Stay at home/sheter in place order in effect if all else is held equal, we expect to see a `r round(model2$coefficients['stay.home.total'] * -1 *  100,3)`% *decrease* in Covid19 cases. This is a very large number, and because it has a small p-value we are sure that there is a relationship. This speaks strongly to the efficacy of such orders, and the low p-value (`r round(coeftest(model2, vcov=cov2)[4,4],3)`) gives us reason to believe that there is a relatively low chance this relationship exists by chance.

Inspection of the Interstate Travel Quarantine In Place Length leads to a similiar result. We see that the p-value is low enough (`r round(coeftest(model2, vcov=cov2)[5,4],3)`) that we should reject the idea that restricting travel does not affect Covid19 cases. The effect size (1 more day of restricting interstate travel leads to `r round(model2$coefficients['travel.total'] * -100,3)`% decrease in Covid19 cases, all else held equal) is nearly as large as the Stay at home/shelter in place order, meaning that they have relatively similar effects on Covid19 cases.

When we inspect the Business mask mandate variable, we find something surprising: it is significant, however it is also positive. This is counterintuitive: we would expect that the longer a mandate for business masks is in place, the lower the number of cases. One explanation for this might be reverse causality. Although we assumed that Business mask mandate influenced Log (Covid-19 Cases), it is possible that Log (Covid-19 Cases) also influenced Business mask mandate. For example, as the number of Covid19 cases increased, states lengthened or reenacted their business mask mandates as a result/in reaction to rising cases. This would explain why, according to our model, every 1 days of increased business mask mandate is associated with a `r round(model2$coefficients['maskB.total'] * 100,3)`% increase in Covid19 cases per 100,000 residents.

## Model 3

For our last model, we add many extra variables. However, none of the additional variables were significant, and the Adjusted $R^2$ actually decreased (from 0.550 to 0.525) compared to the second model, indicating that this model is not efficient. We also seem some interesting effects on the variables that were already in model 2. Stay at home/shelter in place order and Interstate Travel Quarantine In Place Length actually are no longer significant. This might indicate that there exist one or more linear relationships between these two variables and the new variables added. Business mask mandate remains significant though. Log (Population Density) retains its significance (alluding to a very strong relationship). Overall this model does not seem to provide much useful information compared to the previous, simpler models.